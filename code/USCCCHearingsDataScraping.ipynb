{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoFc7rWV7lns"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "from datetime import date\n",
        "\n",
        "\n",
        "# Storage\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sitemap_url = \"https://www.uscc.gov/sitemap.xml\"\n",
        "response = requests.get(sitemap_url)\n",
        "soup = BeautifulSoup(response.text, \"xml\")\n",
        "\n",
        "# Extract all URLs\n",
        "all_urls = [loc.text for loc in soup.find_all(\"loc\")]\n",
        "hearing_urls = sorted(set([u for u in all_urls if \"/hearings/\" in u]))\n",
        "\n",
        "print(\"Total hearings collected:\", len(hearing_urls))\n",
        "print(\"Earliest hearing:\", hearing_urls[0])\n",
        "print(\"Latest hearing:\", hearing_urls[-1])\n",
        "\n",
        "# Helpers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKdzS-Sk7tC0",
        "outputId": "ed60d291-8735-4e68-e9f6-6182ac87d496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total hearings collected: 180\n",
            "Earliest hearing: https://www.uscc.gov/hearings/assessment-ccps-economic-ambitions-plans-and-metrics-success\n",
            "Latest hearing: https://www.uscc.gov/hearings/world-class-military-assessing-chinas-global-military-ambitions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def parse_hearing(url):\n",
        "    r = requests.get(url)\n",
        "    page = BeautifulSoup(r.text, \"lxml\")\n",
        "\n",
        "    # Title\n",
        "    title = page.find(\"h1\").get_text(strip=True) if page.find(\"h1\") else \"\"\n",
        "\n",
        "    # Date (prefer structured element)\n",
        "    date_tag = page.find(\"span\", class_=\"date-display-single\")\n",
        "    if date_tag:\n",
        "        date = date_tag.get_text(strip=True)\n",
        "    else:\n",
        "        # fallback regex\n",
        "        text = page.get_text(\" \", strip=True)\n",
        "        m = re.search(r\"(January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{1,2},\\s+\\d{4}\", text)\n",
        "        date = m.group(0) if m else \"\"\n",
        "\n",
        "    # Transcript(s)\n",
        "    transcripts = []\n",
        "    for a in page.find_all(\"a\", href=True):\n",
        "        if \"Transcript\" in a.text or \"Transcript\" in a[\"href\"]:\n",
        "            link = \"https://www.uscc.gov\" + a[\"href\"] if a[\"href\"].startswith(\"/\") else a[\"href\"]\n",
        "            transcripts.append(link)\n",
        "    transcript_link = \"; \".join(transcripts) if transcripts else None\n",
        "\n",
        "    # Speakers\n",
        "    speakers = []\n",
        "\n",
        "    # Case 1: Bio PDFs\n",
        "    for a in page.find_all(\"a\", href=True):\n",
        "        if a[\"href\"].endswith(\"_Bio.pdf\"):\n",
        "            name = a[\"href\"].split(\"/\")[-1].replace(\"_Bio.pdf\", \"\").replace(\"_\", \" \")\n",
        "            link = \"https://www.uscc.gov\" + a[\"href\"] if a[\"href\"].startswith(\"/\") else a[\"href\"]\n",
        "            speakers.append({\"hearing_url\": url, \"name\": name, \"profile_url\": link})\n",
        "\n",
        "    # Case 2: Witness sections (catch plain text names too)\n",
        "    for div in page.select(\".field--name-field-witness .field__item\"):\n",
        "        name = div.get_text(\" \", strip=True)\n",
        "        if name and not any(s[\"name\"] == name for s in speakers):\n",
        "            speakers.append({\"hearing_url\": url, \"name\": name, \"profile_url\": None})\n",
        "\n",
        "    return {\n",
        "        \"url\": url,\n",
        "        \"title\": title,\n",
        "        \"date\": date,\n",
        "        \"transcript\": transcript_link,\n",
        "        \"speakers\": speakers\n",
        "    }\n"
      ],
      "metadata": {
        "id": "v0LzD-nS7tKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hearing_data, speaker_data = [], []\n",
        "\n",
        "for i, u in enumerate(hearing_urls, 1):\n",
        "    try:\n",
        "        parsed = parse_hearing(u)\n",
        "\n",
        "        hearing_data.append({\n",
        "            \"url\": parsed[\"url\"],\n",
        "            \"title\": parsed[\"title\"],\n",
        "            \"date\": parsed[\"date\"],\n",
        "            \"transcript\": parsed[\"transcript\"]\n",
        "        })\n",
        "\n",
        "        speaker_data.extend(parsed[\"speakers\"])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error at {u}: {e}\")\n",
        "\n",
        "    # Polite delay\n",
        "    time.sleep(1)\n",
        "\n",
        "    # Checkpoint\n",
        "    if i % 25 == 0:\n",
        "        pd.DataFrame(hearing_data).to_csv(\"checkpoint_hearings.csv\", index=False)\n",
        "        pd.DataFrame(speaker_data).to_csv(\"checkpoint_speakers.csv\", index=False)\n",
        "        print(f\"Checkpoint saved at {i} hearings\")\n",
        "\n",
        "# Final save with today’s date\n",
        "today = date.today().strftime(\"%Y%m%d\")\n",
        "df_master = pd.DataFrame(hearing_data)\n",
        "df_speakers = pd.DataFrame(speaker_data)\n",
        "\n",
        "df_master.to_csv(f\"{today}_uscc_master_hearings.csv\", index=False)\n",
        "df_speakers.to_csv(f\"{today}_uscc_master_speakers.csv\", index=False)\n",
        "\n",
        "print(\"Scraping complete ✅\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-3JVWvV7tMu",
        "outputId": "c746dd28-1a2f-4015-9ed8-41c6379f5992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved at 25 hearings\n",
            "Checkpoint saved at 50 hearings\n",
            "Checkpoint saved at 75 hearings\n",
            "Checkpoint saved at 100 hearings\n",
            "Checkpoint saved at 125 hearings\n",
            "Checkpoint saved at 150 hearings\n",
            "Checkpoint saved at 175 hearings\n",
            "Scraping complete ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.uscc.gov/hearings/assessment-ccps-economic-ambitions-plans-and-metrics-success\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "speakers = []\n",
        "for block in soup.select(\".views-row\"):\n",
        "    name = block.select_one(\".views-field-title\").get_text(strip=True) if block.select_one(\".views-field-title\") else None\n",
        "    affiliation = block.select_one(\".views-field-field-speaker-affiliation\").get_text(strip=True) if block.select_one(\".views-field-field-speaker-affiliation\") else None\n",
        "    speakers.append((name, affiliation))\n",
        "\n",
        "print(speakers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC0k3GaV7tP8",
        "outputId": "15fde0f7-dfe9-423a-88c2-9cf5deb3f435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(soup.prettify()[:2000])  # show first 2000 chars\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnyrO4kz7tS9",
        "outputId": "c14c2986-d7f3-428e-b6e0-ed45d42a5331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!--\n",
            "\n",
            "                            _                       _     _\n",
            "                           | |                     | |   (_)\n",
            "      _ __   _____      __ | |_ __ _ _ __ __ _  ___| |_   _ _ __   ___\n",
            "     | '_ \\ / _ \\ \\ /\\ / / | __/ _` | '__/ _` |/ _ \\ __| | | '_ \\ / __|\n",
            "     | | | |  __/\\ V  V /  | || (_| | | | (_| |  __/ |_  | | | | | (__ _\n",
            "     |_| |_|\\___| \\_/\\_/    \\__\\__,_|_|  \\__, |\\___|\\__| |_|_| |_|\\___(_)\n",
            "                                          __/ |\n",
            "                                         |___/\n",
            "\n",
            "     We create digital marketing strategies and design compelling websites.\n",
            "                            www.newtarget.com\n",
            "\n",
            "-->\n",
            "<!DOCTYPE html>\n",
            "<html dir=\"ltr\" lang=\"en\" prefix=\"content: http://purl.org/rss/1.0/modules/content/  dc: http://purl.org/dc/terms/  foaf: http://xmlns.com/foaf/0.1/  og: http://ogp.me/ns#  rdfs: http://www.w3.org/2000/01/rdf-schema#  schema: http://schema.org/  sioc: http://rdfs.org/sioc/ns#  sioct: http://rdfs.org/sioc/types#  skos: http://www.w3.org/2004/02/skos/core#  xsd: http://www.w3.org/2001/XMLSchema# \">\n",
            " <head>\n",
            "  <meta content=\"IE=edge,chrome=1\" http-equiv=\"X-UA-Compatible\"/>\n",
            "  <meta charset=\"utf-8\"/>\n",
            "  <meta content=\"The hearing examines the Chinese Communist Party's economic ambitions, shifts in decision making, and prospects for success. The first panel discusses the current political and economic conditions and policy decisions in China, with an assessment of the risks and metrics shaping the CCP's policy decisions. The second panel examines the tools, trends, and techniques observed in China's economic development heading into the 14th Five Year Plan (2021-2025) and beyond. The third panel examines certain emerging technologies and sectors that the CCP has identified as key enablers for growth and where the CCP has focused efforts on expanding global market position, as well as the implications for U.S. businesses and workers. The fourth panel examines China's rapid expansion of the financial technology sector, mobile paymen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pdfplumber\n",
        "from io import BytesIO\n",
        "\n",
        "url = \"https://www.uscc.gov/sites/default/files/2021-04/Matt_Pottinger_Testimony.pdf\"\n",
        "response = requests.get(url)\n",
        "\n",
        "with pdfplumber.open(BytesIO(response.content)) as pdf:\n",
        "    text = \"\"\n",
        "    for page in pdf.pages:\n",
        "        text += page.extract_text() + \"\\n\"\n",
        "\n",
        "print(text[:1000])  # preview first 1000 chars\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "GEg9VYxH7tUy",
        "outputId": "4ba5e3e0-736e-46a7-a923-df4a6b6c02c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pdfplumber'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3914024135.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpdfplumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.uscc.gov/sites/default/files/2021-04/Matt_Pottinger_Testimony.pdf\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pdfplumber'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OW-ZsAO7tYc",
        "outputId": "e949f7a6-3156-41ac-89c1-c049cea4f5df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.23)\n",
            "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n"
      ],
      "metadata": {
        "id": "_TDzEABPI2ES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyL3UHV2I34k",
        "outputId": "69f64fae-8ee4-4b86-9dd7-18fbfc7e8c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ef2rP8LTI-Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FyX9z5ACI-PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OTI2XpiNI-Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "url = \"https://www.uscc.gov/sites/default/files/2021-04/Matt_Pottinger_Testimony.pdf\"\n",
        "response = requests.get(url)\n",
        "\n",
        "doc = fitz.open(stream=BytesIO(response.content), filetype=\"pdf\")\n",
        "text = \"\"\n",
        "for page in doc:\n",
        "    text += page.get_text()\n",
        "\n",
        "print(text[:1000])  # preview first 1000 chars\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-f3DGgOII5Sd",
        "outputId": "bda2846f-7657-4218-cd80-ca912e0b903f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 \n",
            " \n",
            "15 April 2021 \n",
            " \n",
            "Statement of Matt Pottinger \n",
            " \n",
            "Distinguished Visiting Fellow at the Hoover Institution, \n",
            "Stanford University \n",
            "Former Assistant to the President and Deputy National \n",
            "Security Advisor, the White House \n",
            " \n",
            "Testimony Before the United States-China Economic and \n",
            "Security Review Commission  \n",
            "Chairman Bartholomew, Vice Chairman Dr. Cleveland, and all \n",
            "Commissioners, thank you for the opportunity to speak about the \n",
            "Chinese Communist Party’s economic strategy, and to touch on \n",
            "a few principles that I believe the United States and other free \n",
            "nations should apply as we hone our collective counter-strategy.   \n",
            "The Communist regime’s ambitions really shouldn’t be a \n",
            "mystery to us anymore.  If we listen to what China’s leaders \n",
            "have been saying in their own language, to their own Party \n",
            "members, and cross-reference their rhetoric with their actions, \n",
            "we can see that their plans are hiding in plain sight.   \n",
            "China’s latest Five-Year Plan, published last month, \n",
            "institutionalize\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = text.splitlines()\n",
        "\n"
      ],
      "metadata": {
        "id": "Q26ly_8xI62G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, line in enumerate(lines):\n",
        "    if line.strip().startswith(\"Statement of\"):\n",
        "        name = line.replace(\"Statement of\", \"\").strip()\n",
        "        affiliation = \" \".join(lines[i+1:i+3]).strip()  # take next 1–2 lines\n",
        "        description = \" \".join(lines[i+3:]).strip()\n",
        "        break\n"
      ],
      "metadata": {
        "id": "SJTY4tcIJFmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import pandas as pd\n",
        "\n",
        "# Load your speakers master file\n",
        "speakers_df = pd.read_csv(\"20250929_uscc_master_speakers.csv\")\n",
        "\n",
        "# New columns\n",
        "speakers_df[\"affiliation\"] = \"\"\n",
        "speakers_df[\"description\"] = \"\"\n",
        "\n",
        "def extract_info_from_pdf(pdf_url):\n",
        "    try:\n",
        "        response = requests.get(pdf_url, timeout=20)\n",
        "        response.raise_for_status()\n",
        "        doc = fitz.open(stream=BytesIO(response.content), filetype=\"pdf\")\n",
        "\n",
        "        text = \"\"\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "\n",
        "        lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
        "\n",
        "        name, affiliation, description = None, None, None\n",
        "\n",
        "        for i, line in enumerate(lines):\n",
        "            if line.startswith((\"Statement of\", \"Testimony of\")):\n",
        "                name = line.split(\"of\",1)[-1].strip()\n",
        "                affiliation = \" \".join(lines[i+1:i+3])  # next 1–2 lines\n",
        "                description = \" \".join(lines[i+3:])\n",
        "                break\n",
        "\n",
        "        return name, affiliation, description\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_url}: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "# Loop through all speakers\n",
        "for idx, row in speakers_df.iterrows():\n",
        "    pdf_url = row[\"profile_url\"]\n",
        "    name, affiliation, description = extract_info_from_pdf(pdf_url)\n",
        "\n",
        "    if name:  # only overwrite if found\n",
        "        speakers_df.at[idx, \"name\"] = name\n",
        "    speakers_df.at[idx, \"affiliation\"] = affiliation\n",
        "    speakers_df.at[idx, \"description\"] = description\n",
        "\n",
        "# Save updated file\n",
        "speakers_df.to_csv(\"20250929_uscc_master_speakers_cleaned.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h3DsHYhJGp2",
        "outputId": "7fa43f08-aa0d-4e70-d69f-0f2b3c2e287d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing https://www.uscc.gov/sites/default/files/Panel%20III_Swanstr%C3%B6m_Bio.pdf: 404 Client Error: Not Found for url: https://www.uscc.gov/sites/default/files/Panel%20III_Swanstr%C3%B6m_Bio.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, row in speakers_df.iterrows():\n",
        "    pdf_url = row[\"profile_url\"]\n",
        "\n",
        "    try:\n",
        "        name, affiliation, description = extract_info_from_pdf(pdf_url)\n",
        "\n",
        "        if name:  # only overwrite if found\n",
        "            speakers_df.at[idx, \"name\"] = name\n",
        "        speakers_df.at[idx, \"affiliation\"] = affiliation\n",
        "        speakers_df.at[idx, \"description\"] = description\n",
        "        speakers_df.at[idx, \"bio_status\"] = \"ok\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping {pdf_url}: {e}\")\n",
        "        speakers_df.at[idx, \"bio_status\"] = \"missing_pdf\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSZbJf5fJQi0",
        "outputId": "f527efd4-01fe-407b-de50-aa2e75724ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing https://www.uscc.gov/sites/default/files/Panel%20III_Swanstr%C3%B6m_Bio.pdf: 404 Client Error: Not Found for url: https://www.uscc.gov/sites/default/files/Panel%20III_Swanstr%C3%B6m_Bio.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "speakers_df.to_csv(\"20250929_uscc_master_speakers_cleaned.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "KiYgXpwnMkyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# Test with one speaker's PDF\n",
        "pdf_url = \"https://www.uscc.gov/sites/default/files/2021-04/Matt_Pottinger_Testimony.pdf\"\n",
        "\n",
        "response = requests.get(pdf_url)\n",
        "doc = fitz.open(stream=BytesIO(response.content), filetype=\"pdf\")\n",
        "\n",
        "# Extract text\n",
        "text = \"\"\n",
        "for page in doc:\n",
        "    text += page.get_text()\n",
        "\n",
        "lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
        "\n",
        "name, affiliation, description = None, None, None\n",
        "\n",
        "for i, line in enumerate(lines):\n",
        "    if line.startswith((\"Statement of\", \"Testimony of\")):\n",
        "        name = line.split(\"of\", 1)[-1].strip()\n",
        "        affiliation = \" \".join(lines[i+1:i+3])\n",
        "        description = \" \".join(lines[i+3:i+10])  # first few lines of bio/testimony\n",
        "        break\n",
        "\n",
        "print(\"Name:\", name)\n",
        "print(\"Affiliation:\", affiliation)\n",
        "print(\"Description (preview):\", description[:300], \"...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B1EJhY3MoAD",
        "outputId": "1bf38d4f-b131-45d8-d315-74286e2d8817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Matt Pottinger\n",
            "Affiliation: Distinguished Visiting Fellow at the Hoover Institution, Stanford University\n",
            "Description (preview): Former Assistant to the President and Deputy National Security Advisor, the White House Testimony Before the United States-China Economic and Security Review Commission Chairman Bartholomew, Vice Chairman Dr. Cleveland, and all Commissioners, thank you for the opportunity to speak about the Chinese  ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_info_from_pdf(pdf_url):\n",
        "    try:\n",
        "        response = requests.get(pdf_url, timeout=20)\n",
        "        response.raise_for_status()\n",
        "        doc = fitz.open(stream=BytesIO(response.content), filetype=\"pdf\")\n",
        "\n",
        "        text = \"\"\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "\n",
        "        lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
        "\n",
        "        name, affiliation, description = None, None, None\n",
        "\n",
        "        for i, line in enumerate(lines):\n",
        "            if line.startswith((\"Statement of\", \"Testimony of\")):\n",
        "                name = line.split(\"of\", 1)[-1].strip()\n",
        "                # Sometimes affiliation spans 2–3 lines\n",
        "                affiliation = \" \".join(lines[i+1:i+4])\n",
        "                # Keep first 8–10 lines as description (bio snippet)\n",
        "                description = \" \".join(lines[i+4:i+12])\n",
        "                break\n",
        "\n",
        "        return name, affiliation, description\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_url}: {e}\")\n",
        "        return None, None, None\n"
      ],
      "metadata": {
        "id": "QTGCB81ROsR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import pandas as pd\n",
        "\n",
        "# Load the full speakers file\n",
        "speakers_df = pd.read_csv(\"20250929_uscc_master_speakers.csv\")\n",
        "\n",
        "def extract_info_from_pdf(pdf_url):\n",
        "    try:\n",
        "        response = requests.get(pdf_url, timeout=20)\n",
        "        response.raise_for_status()\n",
        "        doc = fitz.open(stream=BytesIO(response.content), filetype=\"pdf\")\n",
        "\n",
        "        text = \"\"\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "\n",
        "        lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
        "\n",
        "        name, affiliation, description = None, None, None\n",
        "\n",
        "        if \"Bio.pdf\" in pdf_url:  # handle bios\n",
        "            name = pdf_url.split(\"/\")[-1].replace(\"_Bio.pdf\", \"\").replace(\"_\", \" \")\n",
        "            affiliation = lines[0] if lines else None\n",
        "            description = \" \".join(lines[1:]) if len(lines) > 1 else None\n",
        "        else:  # handle testimonies\n",
        "            keywords = [\"Statement of\", \"Testimony of\", \"Prepared Statement of\", \"Biography of\"]\n",
        "            for i, line in enumerate(lines):\n",
        "                if any(line.startswith(k) for k in keywords):\n",
        "                    name = line.split(\"of\", 1)[-1].strip()\n",
        "                    affiliation = \" \".join(lines[i+1:i+4])\n",
        "                    description = \" \".join(lines[i+4:i+12])\n",
        "                    break\n",
        "\n",
        "        return name, affiliation, description\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_url}: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "\n",
        "# --- Process all speakers ---\n",
        "for idx, row in speakers_df.iterrows():\n",
        "    pdf_url = row[\"profile_url\"]\n",
        "\n",
        "    name, affiliation, description = extract_info_from_pdf(pdf_url)\n",
        "\n",
        "    if name:\n",
        "        speakers_df.at[idx, \"name\"] = name\n",
        "    if affiliation:\n",
        "        speakers_df.at[idx, \"affiliation\"] = affiliation\n",
        "    if description:\n",
        "        speakers_df.at[idx, \"description\"] = description\n",
        "\n",
        "    # progress log every 25 speakers\n",
        "    if idx % 25 == 0:\n",
        "        print(f\"Processed {idx+1}/{len(speakers_df)} -> {name}\")\n",
        "\n",
        "# --- Save enriched dataset ---\n",
        "speakers_df.to_csv(\"uscc_master_speakers_enriched.csv\", index=False)\n",
        "\n",
        "print(\"\\nDone ✅\")\n",
        "print(\"Saved as: uscc_master_speakers_enriched.csv\")\n",
        "print(speakers_df[[\"name\", \"affiliation\", \"description\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7kRiSxaQ8CU",
        "outputId": "a4ca1737-8ca7-4642-d906-21f1be138482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1/431 -> Matt Pottinger\n",
            "Processed 26/431 -> Nis Gr%C3%BCnberg\n",
            "Processed 51/431 -> Timothy Meyer\n",
            "Processed 76/431 -> Tayyab Safdar\n",
            "Processed 101/431 -> John Chen\n",
            "Processed 126/431 -> J Michael Dahm\n",
            "Processed 151/431 -> Jeffrey Becker\n",
            "Processed 176/431 -> Katja Drinhausen\n",
            "Processed 201/431 -> Jim Joholske\n",
            "Processed 226/431 -> Ngor Luong\n",
            "Processed 251/431 -> Shichor\n",
            "Processed 276/431 -> Prasad%2C%20Eswar\n",
            "Processed 301/431 -> Panel%202 Wang\n",
            "Error processing https://www.uscc.gov/sites/default/files/Panel%20III_Swanstr%C3%B6m_Bio.pdf: 404 Client Error: Not Found for url: https://www.uscc.gov/sites/default/files/Panel%20III_Swanstr%C3%B6m_Bio.pdf\n",
            "Processed 326/431 -> David%20Wertime\n",
            "Processed 351/431 -> Julia Friedlander\n",
            "Processed 376/431 -> Yu-Jie Chen\n",
            "Processed 401/431 -> Maureen Thorson\n",
            "Processed 426/431 -> Panel%20II Michael%20Hirson\n",
            "\n",
            "Done ✅\n",
            "Saved as: uscc_master_speakers_enriched.csv\n",
            "              name          affiliation  \\\n",
            "0   Matt Pottinger       Matt Pottinger   \n",
            "1         Miles Yu      Miles Yu, Ph.D.   \n",
            "2     Loren Brandt  Loren Brandt, Ph.D.   \n",
            "3  Jude Blanchette      Jude Blanchette   \n",
            "4        Ling Chen     Ling Chen, Ph.D.   \n",
            "\n",
            "                                         description  \n",
            "0  Distinguished Visiting Fellow, Hoover Institut...  \n",
            "1  Senior Fellow, Hudson Institute; Visiting Fell...  \n",
            "2  Noranda Chair Professor of Economics, Universi...  \n",
            "3  Freeman Chair in China Studies, Center for Str...  \n",
            "4  Assistant Professor of Political Economy, Scho...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"uscc_master_speakers_enriched.csv\")\n",
        "\n",
        "def clean_affiliation(row):\n",
        "    name = row[\"name\"]\n",
        "    aff = str(row[\"affiliation\"]) if pd.notnull(row[\"affiliation\"]) else \"\"\n",
        "    desc = str(row[\"description\"]) if pd.notnull(row[\"description\"]) else \"\"\n",
        "\n",
        "    # 1. If affiliation is just the name, replace with first line of description\n",
        "    if aff.strip() == name.strip() or aff.strip().startswith(name.strip()):\n",
        "        first_line = desc.split(\".\")[0] if desc else \"\"\n",
        "        return first_line\n",
        "\n",
        "    # 2. Remove trailing commas/semicolons\n",
        "    aff = aff.strip(\" ,;\")\n",
        "\n",
        "    # 3. If affiliation is very long, shorten it to first sentence\n",
        "    if len(aff.split(\".\")) > 1:\n",
        "        aff = aff.split(\".\")[0]\n",
        "\n",
        "    return aff\n",
        "\n",
        "df[\"affiliation\"] = df.apply(clean_affiliation, axis=1)\n",
        "\n",
        "# Save cleaned version\n",
        "df.to_csv(\"uscc_master_speakers_cleaned_final.csv\", index=False)\n",
        "\n",
        "print(\"✅ Cleaned file saved as uscc_master_speakers_cleaned_final.csv\")\n",
        "print(df.head(5)[[\"name\", \"affiliation\", \"description\"]])\n"
      ],
      "metadata": {
        "id": "_h-h8tlbRHkQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e49fddc-8b66-4a8b-800a-cce84ae41b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cleaned file saved as uscc_master_speakers_cleaned_final.csv\n",
            "              name                                        affiliation  \\\n",
            "0   Matt Pottinger  Distinguished Visiting Fellow, Hoover Institut...   \n",
            "1         Miles Yu  Senior Fellow, Hudson Institute; Visiting Fell...   \n",
            "2     Loren Brandt  Noranda Chair Professor of Economics, Universi...   \n",
            "3  Jude Blanchette  Freeman Chair in China Studies, Center for Str...   \n",
            "4        Ling Chen  Assistant Professor of Political Economy, Scho...   \n",
            "\n",
            "                                         description  \n",
            "0  Distinguished Visiting Fellow, Hoover Institut...  \n",
            "1  Senior Fellow, Hudson Institute; Visiting Fell...  \n",
            "2  Noranda Chair Professor of Economics, Universi...  \n",
            "3  Freeman Chair in China Studies, Center for Str...  \n",
            "4  Assistant Professor of Political Economy, Scho...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your hearings file\n",
        "hearings_df = pd.read_csv(\"20250929_uscc_master_hearings.csv\")\n",
        "\n",
        "# Filter for missing dates or transcripts\n",
        "missing_rows = hearings_df[hearings_df[\"date\"].isna() | hearings_df[\"transcript\"].isna()]\n",
        "\n",
        "print(missing_rows[[\"url\", \"title\", \"date\", \"transcript\"]])\n"
      ],
      "metadata": {
        "id": "0-AMONI1RHmo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8550c6bb-b5b9-46b4-e3de-323f5f2147a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   url  \\\n",
            "42   https://www.uscc.gov/hearings/field-investigat...   \n",
            "47   https://www.uscc.gov/hearings/hearing-bilatera...   \n",
            "50   https://www.uscc.gov/hearings/hearing-china-an...   \n",
            "52   https://www.uscc.gov/hearings/hearing-china-an...   \n",
            "54   https://www.uscc.gov/hearings/hearing-china-an...   \n",
            "55   https://www.uscc.gov/hearings/hearing-china-an...   \n",
            "56   https://www.uscc.gov/hearings/hearing-china-an...   \n",
            "57   https://www.uscc.gov/hearings/hearing-china-em...   \n",
            "60   https://www.uscc.gov/hearings/hearing-china-tr...   \n",
            "64   https://www.uscc.gov/hearings/hearing-chinas-a...   \n",
            "68   https://www.uscc.gov/hearings/hearing-chinas-e...   \n",
            "72   https://www.uscc.gov/hearings/hearing-chinas-f...   \n",
            "77   https://www.uscc.gov/hearings/hearing-chinas-g...   \n",
            "78   https://www.uscc.gov/hearings/hearing-chinas-g...   \n",
            "80   https://www.uscc.gov/hearings/hearing-chinas-h...   \n",
            "86   https://www.uscc.gov/hearings/hearing-chinas-i...   \n",
            "88   https://www.uscc.gov/hearings/hearing-chinas-m...   \n",
            "90   https://www.uscc.gov/hearings/hearing-chinas-m...   \n",
            "91   https://www.uscc.gov/hearings/hearing-chinas-m...   \n",
            "92   https://www.uscc.gov/hearings/hearing-chinas-m...   \n",
            "94   https://www.uscc.gov/hearings/hearing-chinas-m...   \n",
            "98   https://www.uscc.gov/hearings/hearing-chinas-p...   \n",
            "101  https://www.uscc.gov/hearings/hearing-chinas-p...   \n",
            "103  https://www.uscc.gov/hearings/hearing-chinas-p...   \n",
            "108  https://www.uscc.gov/hearings/hearing-chinas-r...   \n",
            "111  https://www.uscc.gov/hearings/hearing-chinas-s...   \n",
            "113  https://www.uscc.gov/hearings/hearing-chinas-w...   \n",
            "114  https://www.uscc.gov/hearings/hearing-chinese-...   \n",
            "115  https://www.uscc.gov/hearings/hearing-chinese-...   \n",
            "118  https://www.uscc.gov/hearings/hearing-chinese-...   \n",
            "123  https://www.uscc.gov/hearings/hearing-corporat...   \n",
            "128  https://www.uscc.gov/hearings/hearing-extent-g...   \n",
            "131  https://www.uscc.gov/hearings/hearing-impact-m...   \n",
            "133  https://www.uscc.gov/hearings/hearing-impact-u...   \n",
            "134  https://www.uscc.gov/hearings/hearing-impact-u...   \n",
            "138  https://www.uscc.gov/hearings/hearing-issues-b...   \n",
            "139  https://www.uscc.gov/hearings/hearing-library-...   \n",
            "142  https://www.uscc.gov/hearings/hearing-major-in...   \n",
            "144  https://www.uscc.gov/hearings/hearing-prolifer...   \n",
            "146  https://www.uscc.gov/hearings/hearing-sars-chi...   \n",
            "147  https://www.uscc.gov/hearings/hearing-security...   \n",
            "153  https://www.uscc.gov/hearings/hearing-us-china...   \n",
            "154  https://www.uscc.gov/hearings/hearing-us-china...   \n",
            "156  https://www.uscc.gov/hearings/hearing-wto-comp...   \n",
            "167  https://www.uscc.gov/hearings/symposia-transat...   \n",
            "168  https://www.uscc.gov/hearings/technical-briefi...   \n",
            "\n",
            "                                                 title                date  \\\n",
            "42   Field Investigation on China's Impact on the U...    January 30, 2004   \n",
            "47   Hearing: Bilateral Trade Policies and Issues B...      August 2, 2001   \n",
            "50              Hearing: China and the Capital Markets     August 11, 2005   \n",
            "52      Hearing: China and the Future of Globalization        May 20, 2005   \n",
            "54     Hearing on China and the U.S. Rebalance to Asia                 NaN   \n",
            "55   Hearing: China and the WTO: Assessing and Enfo...                 NaN   \n",
            "56   Hearing: China and the WTO - Compliance and Mo...    February 5, 2004   \n",
            "57   Hearing: China as an Emerging Regional and Tec...                 NaN   \n",
            "60        Hearing: China Trade/Sectoral and WTO Issues       June 14, 2001   \n",
            "64                 Hearing on China’s Advanced Weapons   February 23, 2017   \n",
            "68        Hearing: China's Energy Needs and Strategies    October 30, 2003   \n",
            "72   Hearing: China’s Financial System and Monetary...                 NaN   \n",
            "77   Hearing: China’s Growing Global Influence: Obj...                 NaN   \n",
            "78   Hearing: China's Growth as a Regional Economic...    December 4, 2003   \n",
            "80        Hearing: China's High Technology Development                 NaN   \n",
            "86   Hearing: China's Investment and Exchange Rate ...  September 25, 2003   \n",
            "88   Hearing: China’s Media and Information Control...  September 10, 2009   \n",
            "90   Hearing: China's Military Modernization and th...    February 6, 2004   \n",
            "91   Hearing: China’s Military Modernization and Cr...  September 15, 2005   \n",
            "92   Hearing: China's Military Modernization and It...                 NaN   \n",
            "94   Hearing: China’s Military Modernization and U....                 NaN   \n",
            "98   Hearing: China's Presence in the Global Capita...      April 16, 2004   \n",
            "101  Hearing: China's Proliferation Practices and t...       July 24, 2003   \n",
            "103  Hearing: China's Proliferation Practices and R...      March 10, 2005   \n",
            "108  Hearing: China’s Role in the World - Is China ...                 NaN   \n",
            "111  Hearing: China's State Control Mechanisms and ...      April 14, 2005   \n",
            "113  Hearing: China’s WTO Compliance and Industrial...       April 4, 2006   \n",
            "114  Hearing: The Chinese Budget and The Role of Th...    December 7, 2001   \n",
            "115  Hearing: Chinese Fundraising Activities in U.S...    December 6, 2001   \n",
            "118  Hearing: Chinese Leadership Succession and Its...  September 23, 2002   \n",
            "123  Hearing: Corporate Accountability, Access to C...                 NaN   \n",
            "128  Hearing: The Extent of the Government’s Contro...                 NaN   \n",
            "131  Hearing: Impact Of Military And Dual-Use Techn...    January 17, 2002   \n",
            "133  Hearing: The Impact of U.S.-China Trade and In...  September 23, 2004   \n",
            "134  Hearing: The Impact of U.S.-China Trade and In...    January 13, 2005   \n",
            "138  Hearing: Issues to be Addressed at the Hong Ko...    December 8, 2005   \n",
            "139  Hearing: The Library of Congress Chinese Langu...  September 16, 2005   \n",
            "142  Hearing: Major Internal Challenges Facing the ...    February 2, 2006   \n",
            "144                    Hearing: Proliferation Policies    October 12, 2001   \n",
            "146  Hearing: SARS in China - Implications for Medi...        June 5, 2003   \n",
            "147   Hearing: Security Issues - Strategic Perceptions      August 3, 2001   \n",
            "153  Hearing: The U.S.-China Relationship: Economic...                 NaN   \n",
            "154  Hearing: U.S.-China Trade Impacts on the U.S. ...       June 23, 2005   \n",
            "156        Hearing: WTO Compliance and Sectoral Issues    January 18, 2002   \n",
            "167  Symposia on Transatlantic Perspectives on Econ...                 NaN   \n",
            "168  Technical Briefing - Corruption's Impact on Go...      August 3, 2001   \n",
            "\n",
            "                                            transcript  \n",
            "42                                                 NaN  \n",
            "47                                                 NaN  \n",
            "50                                                 NaN  \n",
            "52                                                 NaN  \n",
            "54   https://www.uscc.gov/sites/default/files/trans...  \n",
            "55                                                 NaN  \n",
            "56                                                 NaN  \n",
            "57                                                 NaN  \n",
            "60                                                 NaN  \n",
            "64                                                 NaN  \n",
            "68                                                 NaN  \n",
            "72   https://www.uscc.gov/sites/default/files/trans...  \n",
            "77                                                 NaN  \n",
            "78                                                 NaN  \n",
            "80                                                 NaN  \n",
            "86                                                 NaN  \n",
            "88                                                 NaN  \n",
            "90                                                 NaN  \n",
            "91                                                 NaN  \n",
            "92   https://www.uscc.gov/sites/default/files/trans...  \n",
            "94                                                 NaN  \n",
            "98                                                 NaN  \n",
            "101                                                NaN  \n",
            "103                                                NaN  \n",
            "108                                                NaN  \n",
            "111                                                NaN  \n",
            "113                                                NaN  \n",
            "114                                                NaN  \n",
            "115                                                NaN  \n",
            "118                                                NaN  \n",
            "123  https://www.uscc.gov/sites/default/files/trans...  \n",
            "128  https://www.uscc.gov/sites/default/files/trans...  \n",
            "131                                                NaN  \n",
            "133                                                NaN  \n",
            "134                                                NaN  \n",
            "138                                                NaN  \n",
            "139                                                NaN  \n",
            "142                                                NaN  \n",
            "144                                                NaN  \n",
            "146                                                NaN  \n",
            "147                                                NaN  \n",
            "153  https://www.uscc.gov/sites/default/files/trans...  \n",
            "154                                                NaN  \n",
            "156                                                NaN  \n",
            "167                                                NaN  \n",
            "168                                                NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "test_url = missing_rows.iloc[0][\"url\"]  # take the first missing one\n",
        "response = requests.get(test_url)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "# Get date\n",
        "date = soup.select_one(\".field--name-field-hearing-date\")\n",
        "date = date.get_text(strip=True) if date else None\n",
        "\n",
        "# Get transcript link (PDF)\n",
        "transcript_link = None\n",
        "for a in soup.find_all(\"a\", href=True):\n",
        "    if a[\"href\"].endswith(\".pdf\") and \"Transcript\" in a.text:\n",
        "        transcript_link = \"https://www.uscc.gov\" + a[\"href\"]\n",
        "        break\n",
        "\n",
        "print(\"Date:\", date)\n",
        "print(\"Transcript:\", transcript_link)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX0V0e9BXAzh",
        "outputId": "79085875-fdea-4a74-a553-48fee681af70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date: None\n",
            "Transcript: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, row in hearings_df.iterrows():\n",
        "    if pd.isna(row[\"date\"]) or pd.isna(row[\"transcript\"]):\n",
        "        response = requests.get(row[\"url\"])\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        # Date\n",
        "        date = soup.select_one(\".field--name-field-hearing-date\")\n",
        "        if date:\n",
        "            hearings_df.at[idx, \"date\"] = date.get_text(strip=True)\n",
        "\n",
        "        # Transcript\n",
        "        transcript_link = None\n",
        "        for a in soup.find_all(\"a\", href=True):\n",
        "            if a[\"href\"].endswith(\".pdf\") and \"Transcript\" in a.text:\n",
        "                transcript_link = \"https://www.uscc.gov\" + a[\"href\"]\n",
        "                break\n",
        "        if transcript_link:\n",
        "            hearings_df.at[idx, \"transcript\"] = transcript_link\n"
      ],
      "metadata": {
        "id": "o7NXIorrXIov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hearings_df.to_csv(\"uscc_master_hearings_cleaned.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "6vWp_CFVXKMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "hearings_cleaned_df = pd.read_csv(\"uscc_master_hearings_cleaned.csv\")\n"
      ],
      "metadata": {
        "id": "Z6AtPsuHXzRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_rows = hearings_cleaned_df[\n",
        "    hearings_cleaned_df[\"date\"].isna() | hearings_cleaned_df[\"transcript\"].isna()\n",
        "]\n",
        "print(missing_rows.head(3)[[\"url\", \"title\", \"date\", \"transcript\"]])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG9_Egr4XLiK",
        "outputId": "d07e4140-248b-48a4-9c53-57001d228733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  url  \\\n",
            "42  https://www.uscc.gov/hearings/field-investigat...   \n",
            "47  https://www.uscc.gov/hearings/hearing-bilatera...   \n",
            "50  https://www.uscc.gov/hearings/hearing-china-an...   \n",
            "\n",
            "                                                title              date  \\\n",
            "42  Field Investigation on China's Impact on the U...  January 30, 2004   \n",
            "47  Hearing: Bilateral Trade Policies and Issues B...    August 2, 2001   \n",
            "50             Hearing: China and the Capital Markets   August 11, 2005   \n",
            "\n",
            "   transcript  \n",
            "42        NaN  \n",
            "47        NaN  \n",
            "50        NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_name(name, affiliation):\n",
        "    # Remove artifacts like \"Panel%203\"\n",
        "    name = re.sub(r\"Panel.*\", \"\", name, flags=re.IGNORECASE).strip()\n",
        "\n",
        "    # Remove academic suffixes\n",
        "    name = re.sub(r\",?\\s*(Ph\\.D\\.|M\\.D\\.|J\\.D\\.)\", \"\", name, flags=re.IGNORECASE).strip()\n",
        "\n",
        "    # Fix spacing/capitalization\n",
        "    name = \" \".join(name.split())\n",
        "\n",
        "    # Add honorifics (optional)\n",
        "    if \"Professor\" in str(affiliation) or \"Doctor\" in str(affiliation):\n",
        "        name = \"Dr. \" + name\n",
        "    elif name and not name.startswith((\"Mr.\", \"Ms.\", \"Dr.\")):\n",
        "        name = \"Mr. \" + name\n",
        "\n",
        "    return name\n"
      ],
      "metadata": {
        "id": "De4IKnvNXr90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speakers_df[\"name_clean\"] = speakers_df.apply(\n",
        "    lambda row: clean_name(row[\"name\"], row[\"affiliation\"]), axis=1\n",
        ")\n",
        "\n",
        "# Preview\n",
        "print(speakers_df[[\"name\", \"name_clean\"]].head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbsCbd17YMXA",
        "outputId": "6d4fe07d-7909-4596-d1a2-dcc098d2e40b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               name            name_clean\n",
            "0    Matt Pottinger    Mr. Matt Pottinger\n",
            "1          Miles Yu          Mr. Miles Yu\n",
            "2      Loren Brandt      Mr. Loren Brandt\n",
            "3   Jude Blanchette   Mr. Jude Blanchette\n",
            "4         Ling Chen         Mr. Ling Chen\n",
            "5        Nigel Cory        Mr. Nigel Cory\n",
            "6       Jason Kelly       Mr. Jason Kelly\n",
            "7      Joanna Moody      Mr. Joanna Moody\n",
            "8  Martin Chorzempa  Mr. Martin Chorzempa\n",
            "9      Yaya Fanusie      Mr. Yaya Fanusie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_name(name, affiliation):\n",
        "    # Remove artifacts like Panel%20\n",
        "    name = re.sub(r\"Panel.*\", \"\", str(name), flags=re.IGNORECASE).strip()\n",
        "    # Remove academic suffixes (Ph.D., M.D., J.D.)\n",
        "    name = re.sub(r\",?\\s*(Ph\\.D\\.|M\\.D\\.|J\\.D\\.)\", \"\", name, flags=re.IGNORECASE).strip()\n",
        "    # Fix spacing\n",
        "    name = \" \".join(name.split())\n",
        "\n",
        "    # Add Dr. only if affiliation suggests it\n",
        "    if \"Professor\" in str(affiliation) or \"Doctor\" in str(affiliation):\n",
        "        if not name.startswith(\"Dr. \"):\n",
        "            name = \"Dr. \" + name\n",
        "\n",
        "    return name\n",
        "\n",
        "# Apply cleanup\n",
        "speakers_df[\"name_clean\"] = speakers_df.apply(\n",
        "    lambda row: clean_name(row[\"name\"], row[\"affiliation\"]), axis=1\n",
        ")\n",
        "\n",
        "# Preview\n",
        "print(speakers_df[[\"name\", \"affiliation\", \"name_clean\"]].head(15))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWd73nkhYMZp",
        "outputId": "f979913f-f126-46e4-b24f-5241ced573e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     name                affiliation             name_clean\n",
            "0          Matt Pottinger             Matt Pottinger         Matt Pottinger\n",
            "1                Miles Yu            Miles Yu, Ph.D.               Miles Yu\n",
            "2            Loren Brandt        Loren Brandt, Ph.D.           Loren Brandt\n",
            "3         Jude Blanchette            Jude Blanchette        Jude Blanchette\n",
            "4               Ling Chen           Ling Chen, Ph.D.              Ling Chen\n",
            "5              Nigel Cory                 Nigel Cory             Nigel Cory\n",
            "6             Jason Kelly         Jason Kelly, Ph.D.            Jason Kelly\n",
            "7            Joanna Moody        Joanna Moody, Ph.D.           Joanna Moody\n",
            "8        Martin Chorzempa           Martin Chorzempa       Martin Chorzempa\n",
            "9            Yaya Fanusie               Yaya Fanusie           Yaya Fanusie\n",
            "10            Sam Hoffman    Samantha Hoffman, Ph.D.            Sam Hoffman\n",
            "11  Andrea Kendall-Taylor  Dr. Andrea Kendall-Taylor  Andrea Kendall-Taylor\n",
            "12     Christopher Walker         Christopher Walker     Christopher Walker\n",
            "13    Christopher Chivvis    Dr. Christopher Chivvis    Christopher Chivvis\n",
            "14       Kimberly Donovan           Kimberly Donovan       Kimberly Donovan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lK0ZaQ0QYMci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "muaEW5v_YMfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lB-wizkjYMiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cbOxrtXnYMkm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}