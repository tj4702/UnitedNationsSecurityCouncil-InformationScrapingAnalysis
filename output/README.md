# Exploring the USCC Hearings Datasets

As part of my project on **scraping and structuring data from the U.S.â€“China Economic and Security Review Commission (USCC)** hearings, I generated two key outputs:

* `uscc_master_hearings.csv`
* `uscc_master_speakers.csv`

Together, they provide a structured window into how the United States publicly documents and debates its evolving relationship with China. Letâ€™s break down what each dataset contains, how it was built, and why it matters.

---

## ğŸ“‚ 1. Master Hearings Dataset (`uscc_master_hearings.csv`)

This file captures **one row per hearing**. Think of it as the â€œindexâ€ of all hearings in the USCC archive.

### Columns:

* **date** â†’ Standardized as `YYYY-MM-DD`, making it easy to sort and filter by year, month, or even analyze seasonal trends in hearings.
* **title** â†’ The official title of the hearing (e.g., *â€œAn Axis of Autocracy? Chinaâ€™s Relations with Russia, Iran, and North Koreaâ€*). Titles are rich signals of what topics were prioritized in U.S. policy discussions at the time.
* **url** â†’ The link to the hearingâ€™s landing page. This acts as your gateway to full context (agendas, background documents).
* **transcript_url** â†’ Direct PDF link to the hearing transcript. This makes it possible to run **NLP pipelines** (topic modeling, keyword extraction, sentiment analysis) without manually hunting for files.

### Why it matters:

This dataset gives you the **timeline of hearings**, allowing for trend analysis:

* How often hearings are held.
* Shifts in thematic focus (e.g., economics in one period, tech security in another).
* Easy cross-linking with external world events (trade wars, Taiwan tensions, etc.).

---

## ğŸ“‚ 2. Master Speakers Dataset (`uscc_master_speakers.csv`)

While the hearings dataset tells you **when** and **what**, this file tells you **who** is shaping the conversation.

### Columns:

* **hearing_date** & **hearing_title** â†’ These keys link each speaker back to their hearing in the master dataset.
* **speaker_name** â†’ Cleaned speaker names (standardized to remove artifacts like â€œPanel%203â€).
* **speaker_organization** â†’ Affiliation, which is crucial for mapping **institutional influence** (e.g., think tanks, government agencies, academia).
* **speaker_profile_url** â†’ Links to individual bios when available, useful for deeper profiling.

### Why it matters:

This dataset allows for **network analysis of voices in U.S.â€“China debates**:

* Which experts are called most frequently.
* Which think tanks, agencies, or universities dominate testimony.
* How representation changes over time (e.g., more tech-sector voices in later years).

---

## ğŸ§© Putting It All Together

The beauty of these two datasets is that they complement each other:

* `uscc_master_hearings.csv` gives the **macro picture** (timeline + topics).
* `uscc_master_speakers.csv` gives the **micro picture** (who spoke, from where, when).

Together, they form the foundation for:

* **Tableau / Power BI Dashboards** â†’ frequency of hearings, speaker affiliation breakdowns.
* **NLP Research** â†’ topic modeling of transcripts.
* **Network Graphs** â†’ mapping institutional ecosystems in U.S.â€“China policy debates.

---

This is more than just scraping â€” itâ€™s about transforming **static government web pages** into a **living dataset** that opens new avenues for research, visualization, and policy insight.


