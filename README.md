# USCC Hearings Dataset & Scraper

This project collects, cleans, and structures data from the **U.S.â€“China Economic and Security Review Commission (USCC)** hearings. These hearings feature testimony from policymakers, academics, and experts, and provide key insights into the economic, political, and security dimensions of U.S.â€“China relations.

The dataset created here supports downstream research and visualization, forming part of a broader effort to map Chinaâ€™s global engagements (see also: *China Diplomatic Visits Dashboard*).

---

## ğŸ“Œ Objective

* Build a **structured dataset** of USCC hearings and speakers.
* Extract **hearing-level metadata**: date, title, URL, transcript link.
* Extract **speaker-level details**: name, affiliation, profile URL.
* Produce **two CSVs** for analysis and dashboarding.

---

## ğŸ“‚ Repository Structure

```
.
â”œâ”€ code/
â”‚  â””â”€ USCCCHearingsDataScraping.ipynb                 # Final Jupyter Notebook scraper
â”‚
â”œâ”€ output/
â”‚  â”œâ”€ uscc_master_hearings.csv    # Hearing-level dataset
â”‚  â””â”€ uscc_master_speakers.csv    # Speaker-level dataset
â”‚
â””â”€ README.md                      # Project documentation
```

---

## ğŸ› ï¸ Methodology

* **Archive pagination**: Crawl `https://www.uscc.gov/hearings?type=hearing&page=N`.
* **Hearing pages**: Extract hearing date, title, transcript URL.
* **Speakers**: Collect speaker names, affiliations, and profile links.
* **Output**: Save standardized CSVs for reproducibility.

---

## ğŸ“Š Output

* **Master Hearings CSV** â†’ 1 row per hearing
* **Speakers CSV** â†’ 1 row per speaker per hearing

These datasets can be used for analysis in Python, R, Tableau, or Power BI.

---



## ğŸ”§ Technologies Used

* Python (Requests, BeautifulSoup, Pandas)
* Jupyter Notebooks
* CSV

---

